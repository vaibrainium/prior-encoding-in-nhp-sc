{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from notebooks.imports import *\n",
    "from config import dir_config\n",
    "from src.utils.glm_hmm_utils import *\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_dir = Path(dir_config.data.compiled)\n",
    "processed_dir = Path(dir_config.data.processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TRIALS = \"all_trials\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_previous_data(trial_data, invalid_idx):\n",
    "\tnpr.seed(1)\n",
    "\tprev_choice = np.hstack([trial_data.choice[0], trial_data.choice[:-1]])  # 0:awayRF, 1:toRF of previous valid trial\n",
    "\tprev_target = np.hstack([trial_data.target[0], trial_data.target[:-1]]) * 2 - 1  # -1:awayRF, 1:toRF of previous valid trial\n",
    "\n",
    "\t# indices where the previous trial is invalid/valid\n",
    "\tprev_invalid_idx = np.array(invalid_idx) + 1\n",
    "\tif 0 in invalid_idx:\n",
    "\t\tprev_invalid_idx = np.append(0, prev_invalid_idx)\n",
    "\tprev_valid_idx = np.setdiff1d(np.arange(len(trial_data)), prev_invalid_idx)\n",
    "\n",
    "\tfor i in prev_invalid_idx[prev_invalid_idx < len(trial_data)]:\n",
    "\t\tif i < prev_valid_idx[0]:  # randomly sample if no previous valid trials\n",
    "\t\t\tprev_choice[i] = np.random.binomial(1, 0.5)\n",
    "\t\t\tprev_target[i] = np.random.binomial(1, 0.5) * 2 - 1\n",
    "\t\telse:\n",
    "\t\t\tlast_valid = np.where(prev_valid_idx < i)[0][-1]\n",
    "\t\t\tprev_choice[i] = prev_choice[prev_valid_idx[last_valid]]\n",
    "\t\t\tprev_target[i] = prev_target[prev_valid_idx[last_valid]]\n",
    "\n",
    "\tprev_choice = (prev_choice * 2) - 1  # -1:awayRF, 1:toRF of previous valid trial\n",
    "\treturn prev_choice.astype(int), prev_target.astype(int)\n",
    "\n",
    "\n",
    "def prepare_input_data(data, input_dim, invalid_idx):\n",
    "\tX = np.ones((1, data.shape[0], input_dim))\n",
    "\n",
    "\tcurrent_stimulus = data.coherence * (2 * data.target - 1)\n",
    "\tcurrent_stimulus = current_stimulus / 100\n",
    "\n",
    "\tX[0, :, 0] = current_stimulus\n",
    "\tX[0, :, 2], X[0, :, 3] = extract_previous_data(data, invalid_idx)\n",
    "\treturn list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create design matrix (input, output, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2  # number of discrete states\n",
    "obs_dim = 1  # number of observed dimensions: choice(toRF/awayRF)\n",
    "num_categories = 2  # number of categories for output\n",
    "input_dim = 4  # input dimensions: current signed coherence, 1(bias), previous choice(toRF/awayRF), previous target side(toRF/awayRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_metadata = pd.read_csv(Path(compiled_dir, \"sessions_metadata.csv\"), index_col=None)\n",
    "inputs_session_wise = []\n",
    "choices_session_wise = []\n",
    "invalid_idx_session_wise = []\n",
    "masks_session_wise = []\n",
    "GP_trial_num_session_wise = []\n",
    "prob_toRF_session_wise = []\n",
    "reaction_time_session_wise = []\n",
    "\n",
    "for session_id in session_metadata[\"session_id\"]:\n",
    "\ttrial_data = pd.read_csv(Path(compiled_dir, session_id, f\"{session_id}_trial.csv\"), index_col=None)\n",
    "\tGP_trial_data = trial_data[trial_data.task_type == 1].reset_index()\n",
    "\tGP_trial_data.choice = GP_trial_data.choice.fillna(-1)\n",
    "\tGP_trial_data.target = GP_trial_data.target.fillna(-1)\n",
    "\tGP_trial_data.outcome = GP_trial_data.outcome.fillna(-1)\n",
    "\n",
    "\tinvalid_idx = np.where(GP_trial_data.outcome < 0)[0]\n",
    "\tvalid_idx = np.where(GP_trial_data.outcome >= 0)[0]\n",
    "\n",
    "\tinputs = prepare_input_data(GP_trial_data, input_dim, invalid_idx)\n",
    "\tchoices = GP_trial_data.choice.values.reshape(-1, 1).astype(\"int\")\n",
    "\n",
    "\tif _TRIALS == \"all_trials\":\n",
    "\t\t# for training, replace -1 with random sample from 0,1\n",
    "\t\tchoices[choices == -1] = npr.choice(1, invalid_idx.shape[0])\n",
    "\t\tmask = np.ones_like(choices, dtype=bool)\n",
    "\t\tmask[invalid_idx] = 0\n",
    "\t\tGP_trial_num = np.array(GP_trial_data.trial_number)\n",
    "\t\tprob_toRF = np.array(GP_trial_data.prob_toRF)\n",
    "\t\treaction_time = np.array(GP_trial_data.reaction_time)\n",
    "\n",
    "\telif _TRIALS == \"valid_only\":\n",
    "\t\tchoices = choices[valid_idx, :]\n",
    "\t\tinputs[0] = inputs[0][valid_idx, :]\n",
    "\t\tmask = np.ones_like(choices, dtype=bool)\n",
    "\t\tGP_trial_num = np.array(GP_trial_data.trial_number)[valid_idx]\n",
    "\t\tprob_toRF = np.array(GP_trial_data.prob_toRF)[valid_idx]\n",
    "\t\treaction_time = np.array(GP_trial_data.reaction_time)[valid_idx]\n",
    "\n",
    "\tmasks_session_wise.append(mask)\n",
    "\tinputs_session_wise += inputs\n",
    "\tchoices_session_wise.append(choices)\n",
    "\tGP_trial_num_session_wise.append(GP_trial_num)\n",
    "\tprob_toRF_session_wise.append(prob_toRF)\n",
    "\treaction_time_session_wise.append(reaction_time)\n",
    "\n",
    "\n",
    "inputs_aggregated, choices_aggregated, masks_aggregated = [], [], []\n",
    "inputs_aggregated.append(np.vstack(inputs_session_wise))\n",
    "choices_aggregated.append(np.vstack(choices_session_wise))\n",
    "masks_aggregated.append(np.vstack(masks_session_wise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_inputs_session_wise = copy.deepcopy(inputs_session_wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prior toRF sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "toRF_prior_session_idx = np.where(session_metadata.prior_direction == \"toRF\")[0]\n",
    "inputs_aggregated_toRF_prior, choices_aggregated_toRF_prior, masks_aggregated_toRF_prior = [], [], []\n",
    "inputs_aggregated_toRF_prior.append(np.vstack([inputs_session_wise[i] for i in toRF_prior_session_idx]))\n",
    "choices_aggregated_toRF_prior.append(np.vstack([choices_session_wise[i] for i in toRF_prior_session_idx]))\n",
    "masks_aggregated_toRF_prior.append(np.vstack([masks_session_wise[i] for i in toRF_prior_session_idx]))\n",
    "unnormalized_inputs_aggregated_toRF_prior = copy.deepcopy(inputs_aggregated_toRF_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling signed coherence\n",
    "inputs_aggregated_toRF_prior[0][masks_aggregated_toRF_prior[0][:, 0], 0] = preprocessing.scale(inputs_aggregated_toRF_prior[0][masks_aggregated_toRF_prior[0][:, 0], 0], axis=0)\n",
    "for idx_session in range(len(session_metadata)):\n",
    "\tinputs_session_wise[idx_session][masks_session_wise[idx_session][:, 0], 0] = preprocessing.scale(inputs_session_wise[idx_session][masks_session_wise[idx_session][:, 0], 0], axis=0)  # normalize signed coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_glm_hmm_toRF_prior, fit_lls_glm_hmm_toRF_prior = global_fit(choices_aggregated_toRF_prior, inputs_aggregated_toRF_prior, masks=masks_aggregated_toRF_prior, n_iters=1000, n_initializations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model of 20 initializations for each state\n",
    "init_params = {\"glm_weights\": {}, \"transition_matrices\": {}}\n",
    "for n_states in np.arange(2, 6):\n",
    "\tbest_idx = fit_lls_glm_hmm_toRF_prior[n_states].index(max(fit_lls_glm_hmm_toRF_prior[n_states]))\n",
    "\tinit_params[\"glm_weights\"][n_states] = models_glm_hmm_toRF_prior[n_states][best_idx].observations.params\n",
    "\tinit_params[\"transition_matrices\"][n_states] = models_glm_hmm_toRF_prior[n_states][best_idx].transitions.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session-wise fitting with 5 fold cross-validation\n",
    "models_session_state_fold_toRF, train_ll_session_toRF, test_ll_session_toRF = session_wise_fit_cv(\n",
    "\t[choices_session_wise[i] for i in toRF_prior_session_idx],\n",
    "\t[inputs_session_wise[i] for i in toRF_prior_session_idx],\n",
    "\tmasks=[masks_session_wise[i] for i in toRF_prior_session_idx],\n",
    "\tn_sessions=len(toRF_prior_session_idx),\n",
    "\tinit_params=init_params,\n",
    "\tn_iters=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prior awayRF sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "awayRF_prior_session_idx = np.where(session_metadata.prior_direction == \"awayRF\")[0]\n",
    "inputs_aggregated_awayRF_prior, choices_aggregated_awayRF_prior, masks_aggregated_awayRF_prior = [], [], []\n",
    "inputs_aggregated_awayRF_prior.append(np.vstack([inputs_session_wise[i] for i in awayRF_prior_session_idx]))\n",
    "choices_aggregated_awayRF_prior.append(np.vstack([choices_session_wise[i] for i in awayRF_prior_session_idx]))\n",
    "masks_aggregated_awayRF_prior.append(np.vstack([masks_session_wise[i] for i in awayRF_prior_session_idx]))\n",
    "unnormalized_inputs_aggregated_awayRF_prior = copy.deepcopy(inputs_aggregated_awayRF_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling signed coherence\n",
    "inputs_aggregated_awayRF_prior[0][masks_aggregated_awayRF_prior[0][:, 0], 0] = preprocessing.scale(inputs_aggregated_awayRF_prior[0][masks_aggregated_awayRF_prior[0][:, 0], 0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_glm_hmm_awayRF_prior, fit_lls_glm_hmm_awayRF_prior = global_fit(choices_aggregated_awayRF_prior, inputs_aggregated_awayRF_prior, masks=masks_aggregated_awayRF_prior, n_iters=1000, n_initializations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model of 20 initializations for each state\n",
    "init_params = {\"glm_weights\": {}, \"transition_matrices\": {}}\n",
    "for n_states in np.arange(2, 6):\n",
    "\tbest_idx = fit_lls_glm_hmm_awayRF_prior[n_states].index(max(fit_lls_glm_hmm_awayRF_prior[n_states]))\n",
    "\tinit_params[\"glm_weights\"][n_states] = models_glm_hmm_awayRF_prior[n_states][best_idx].observations.params\n",
    "\tinit_params[\"transition_matrices\"][n_states] = models_glm_hmm_awayRF_prior[n_states][best_idx].transitions.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session-wise fitting with 5 fold cross-validation\n",
    "models_session_state_fold_awayRF, train_ll_session_awayRF, test_ll_session_awayRF = session_wise_fit_cv(\n",
    "\t[choices_session_wise[i] for i in awayRF_prior_session_idx],\n",
    "\t[inputs_session_wise[i] for i in awayRF_prior_session_idx],\n",
    "\tmasks=[masks_session_wise[i] for i in awayRF_prior_session_idx],\n",
    "\tn_sessions=len(awayRF_prior_session_idx),\n",
    "\tinit_params=init_params,\n",
    "\tn_iters=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ll_session = np.full((len(session_metadata[\"session_id\"]), len(range(2, 6)), 5), np.nan)\n",
    "test_ll_session = np.full((len(session_metadata[\"session_id\"]), len(range(2, 6)), 5), np.nan)\n",
    "models_session_state_fold = {}\n",
    "\n",
    "for toRF_idx, session_idx in enumerate(toRF_prior_session_idx):\n",
    "\tmodels_session_state_fold[session_idx] = models_session_state_fold_toRF[toRF_idx]\n",
    "\ttrain_ll_session[session_idx] = train_ll_session_toRF[toRF_idx]\n",
    "\ttest_ll_session[session_idx] = test_ll_session_toRF[toRF_idx]\n",
    "\n",
    "\n",
    "for awayRF_idx, session_idx in enumerate(awayRF_prior_session_idx):\n",
    "\tmodels_session_state_fold[session_idx] = models_session_state_fold_awayRF[awayRF_idx]\n",
    "\ttrain_ll_session[session_idx] = train_ll_session_awayRF[awayRF_idx]\n",
    "\ttest_ll_session[session_idx] = test_ll_session_awayRF[awayRF_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data and models for aggregated\n",
    "agg_data_toRF_prior = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"choices\": choices_aggregated_toRF_prior[0].reshape(-1),\n",
    "\t\t\"stimulus\": unnormalized_inputs_aggregated_toRF_prior[0][:, 0],\n",
    "\t\t\"normalized_stimulus\": inputs_aggregated_toRF_prior[0][:, 0],\n",
    "\t\t\"bias\": inputs_aggregated_toRF_prior[0][:, 1],\n",
    "\t\t\"previous_choice\": inputs_aggregated_toRF_prior[0][:, 2],\n",
    "\t\t\"previous_target\": inputs_aggregated_toRF_prior[0][:, 3],\n",
    "\t\t\"mask\": masks_aggregated_toRF_prior[0].reshape(-1),\n",
    "\t}\n",
    ")\n",
    "\n",
    "agg_data_awayRF_prior = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"choices\": choices_aggregated_awayRF_prior[0].reshape(-1),\n",
    "\t\t\"stimulus\": unnormalized_inputs_aggregated_awayRF_prior[0][:, 0],\n",
    "\t\t\"normalized_stimulus\": inputs_aggregated_awayRF_prior[0][:, 0],\n",
    "\t\t\"bias\": inputs_aggregated_awayRF_prior[0][:, 1],\n",
    "\t\t\"previous_choice\": inputs_aggregated_awayRF_prior[0][:, 2],\n",
    "\t\t\"previous_target\": inputs_aggregated_awayRF_prior[0][:, 3],\n",
    "\t\t\"mask\": masks_aggregated_awayRF_prior[0].reshape(-1),\n",
    "\t}\n",
    ")\n",
    "\n",
    "global_fits = {\n",
    "\t\"toRF_prior\": {\"models\": models_glm_hmm_toRF_prior, \"fits_lls_glm_hmm\": fit_lls_glm_hmm_toRF_prior, \"data\": agg_data_toRF_prior},\n",
    "\t\"awayRF_prior\": {\"models\": models_glm_hmm_awayRF_prior, \"fits_lls_glm_hmm\": fit_lls_glm_hmm_awayRF_prior, \"data\": agg_data_awayRF_prior},\n",
    "}\n",
    "\n",
    "\n",
    "# store data and models for session-wise\n",
    "session_data = {}\n",
    "for idx_session, session_id in enumerate(session_metadata[\"session_id\"]):\n",
    "\tsession_data[session_id] = pd.DataFrame(\n",
    "\t\t{\n",
    "\t\t\t\"choices\": choices_session_wise[idx_session].reshape(-1),\n",
    "\t\t\t\"stimulus\": unnormalized_inputs_session_wise[idx_session][:, 0],\n",
    "\t\t\t\"normalized_stimulus\": inputs_session_wise[idx_session][:, 0],\n",
    "\t\t\t\"bias\": inputs_session_wise[idx_session][:, 1],\n",
    "\t\t\t\"previous_choice\": inputs_session_wise[idx_session][:, 2],\n",
    "\t\t\t\"previous_target\": inputs_session_wise[idx_session][:, 3],\n",
    "\t\t\t\"mask\": masks_session_wise[idx_session].reshape(-1),\n",
    "\t\t\t\"trial_num\": GP_trial_num_session_wise[idx_session].reshape(-1),\n",
    "\t\t\t\"prob_toRF\": prob_toRF_session_wise[idx_session].reshape(-1),\n",
    "\t\t\t\"reaction_time\": reaction_time_session_wise[idx_session].reshape(-1),\n",
    "\t\t}\n",
    "\t)\n",
    "\n",
    "session_wise_fits = {\n",
    "\t\"models\": models_session_state_fold,\n",
    "\t\"train_ll\": train_ll_session,\n",
    "\t\"test_ll\": test_ll_session,\n",
    "\t\"data\": session_data,\n",
    "}\n",
    "\n",
    "\n",
    "models_and_data = {\n",
    "\t\"global\": global_fits,\n",
    "\t\"session_wise\": session_wise_fits,\n",
    "}\n",
    "\n",
    "with open(Path(processed_dir, f\"glm_hmm_{_TRIALS}_prior_based_initialization.pkl\"), \"wb\") as f:\n",
    "\tpickle.dump(models_and_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prior-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
