{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.init import normal, constant\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "# from attorch.train import early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.3)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from notebooks.imports import *\n",
    "from config import dir_config\n",
    "from src.utils.glm_hmm_utils import *\n",
    "import pickle\n",
    "import copy\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bayesian_encoding.model import Net\n",
    "from src.bayesian_encoding.utils import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_dir = Path(dir_config.data.compiled)\n",
    "processed_dir = Path(dir_config.data.processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject sessions\n",
    "session_to_exclude = [\"210210_GP_JP\",\"241209_GP_TZ\"]\n",
    "\n",
    "session_metadata = pd.read_csv(Path(compiled_dir, \"sessions_metadata.csv\"))\n",
    "neuron_metadata = pd.read_csv(Path(compiled_dir, \"neuron_metadata.csv\"))\n",
    "\n",
    "session_metadata = session_metadata[~session_metadata[\"session_id\"].isin(session_to_exclude)]\n",
    "neuron_metadata = neuron_metadata[~neuron_metadata[\"session_id\"].isin(session_to_exclude)]\n",
    "\n",
    "with open(Path(processed_dir, \"glm_hmm_all_trials_prior_based_initialization_final.pkl\"), \"rb\") as f:\n",
    "\tglm_hmm = pickle.load(f)\n",
    "\n",
    "with open(Path(processed_dir, \"ephys_neuron_wise.pkl\"), \"rb\") as f:\n",
    "\tephys = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh = [-50, -20, -6, 0, 6, 20, 50]\n",
    "\n",
    "equal_prior = np.array([0.125, .125, .125, .25, .125, .125, .125])\n",
    "toRF_prior = np.array([0.075, 0.075, 0.075, 0.25, 0.175, 0.175, 0.175])\n",
    "awayRF_prior = np.array([0.175, 0.175, 0.175, 0.25, 0.075, 0.075, 0.075])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_neural_data(epoch, valid_trial_filter, neuron_ids):\n",
    "\t\"\"\"return 3d array of shape (num_neurons, num_trials, num_time_bins)\"\"\"\n",
    "\tneural_data = []\n",
    "\tfor neuron_id in neuron_ids:\n",
    "\t\tneural_data.append(ephys[epoch][neuron_id]['convolved_spike_trains'])\n",
    "\tneural_data = np.array(neural_data)\n",
    "\tneural_data = neural_data[:, valid_trial_filter, :]\n",
    "\treturn neural_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 48,  41,  27,  48,  14,  33,  46],\n",
       "        [ 41,  27,  13,  86,  61, 100, 108]]),\n",
       " array([[49, 37, 17, 48, 29, 43, 49],\n",
       "        [65, 61, 50, 45,  9, 20, 26]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toRF_trial_freq_by_coh_and_prior = np.empty((len(session_metadata), 2, len(coh)))*np.nan\n",
    "awayRF_trial_freq_by_coh_and_prior = np.empty((len(session_metadata), 2, len(coh)))*np.nan\n",
    "# aggregate all sessions\n",
    "for session_idx, session_id in enumerate(session_metadata.session_id):\n",
    "\ttrial_data = glm_hmm['session_wise']['data'][session_id]\n",
    "\tvalid_trial_filter = np.where((trial_data['mask'] == 1) & (~np.isnan(trial_data['reaction_time'])))[0]\n",
    "\ttrial_data = trial_data.iloc[valid_trial_filter]\n",
    "\ttrial_data = trial_data[\n",
    "\t\t((trial_data['stimulus'] > 0) & (trial_data['choices'] == 1)) |\n",
    "\t\t((trial_data['stimulus'] < 0) & (trial_data['choices'] == 0)) |\n",
    "\t\t(trial_data['stimulus'] == 0)\n",
    "\t]\n",
    "\ttrial_data_count = trial_data.groupby(['prob_toRF', 'stimulus']).size().reset_index(name='freq')\n",
    "\n",
    "\tprior_dir = session_metadata[session_metadata[\"session_id\"] == session_id].prior_direction.values[0]\n",
    "\tif prior_dir == \"toRF\":\n",
    "\t\ttoRF_trial_freq_by_coh_and_prior[session_idx, :, :] = np.array(trial_data_count.freq).reshape(2, len(coh))\n",
    "\telif prior_dir == \"awayRF\":\n",
    "\t\tawayRF_trial_freq_by_coh_and_prior[session_idx, :, :] = np.array(trial_data_count.freq).reshape(2, len(coh))[::-1]\n",
    "\n",
    "# \tif session_metadata[session_metadata[\"session_id\"] == session_id].prior_direction.values[0] == \"toRF\":\n",
    "# \t\ttoRF_trial_freq_by_coh_and_prior[session_idx, :, :] = np.array(trial_data_count.freq).reshape(2, len(coh))\n",
    "# \telif session_metadata[session_metadata[\"session_id\"] == session_id].prior_direction.values[0] == \"awayRF\":\n",
    "# \t\tawayRF_trial_freq_by_coh_and_prior[session_idx, :, :] = np.array(trial_data_count.freq).reshape(2, len(coh))[::-1]\n",
    "\n",
    "toRF_min_trial_per_condition = np.nanmin(toRF_trial_freq_by_coh_and_prior, axis=0).astype(int)\n",
    "awayRF_min_trial_per_condition = np.nanmin(awayRF_trial_freq_by_coh_and_prior, axis=0).astype(int)\n",
    "toRF_min_trial_per_condition, awayRF_min_trial_per_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86, 693, 351), (81, 548, 351))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 'response_onset'\n",
    "agg_toRF_neuron_data = []\n",
    "agg_awayRF_neuron_data = []\n",
    "\n",
    "# randomly draw trials from each session\n",
    "for session_idx, session_id in enumerate(session_metadata.session_id):\n",
    "\ttrial_data = glm_hmm['session_wise']['data'][session_id]\n",
    "\tvalid_trial_filter = np.where((trial_data['mask'] == 1) & (~np.isnan(trial_data['reaction_time'])))[0]\n",
    "\ttrial_data = trial_data.iloc[valid_trial_filter]\n",
    "\ttrial_data = trial_data[\n",
    "\t\t((trial_data['stimulus'] > 0) & (trial_data['choices'] == 1)) |\n",
    "\t\t((trial_data['stimulus'] < 0) & (trial_data['choices'] == 0)) |\n",
    "\t\t(trial_data['stimulus'] == 0)\n",
    "\t]\n",
    "\n",
    "\tneuron_ids = neuron_metadata.neuron_id[neuron_metadata.session_id == session_id].values\n",
    "\n",
    "\ttoRF_trial_indices = {'eq': [], 'uneq': []}\n",
    "\tawayRF_trial_indices = {'eq': [], 'uneq': []}\n",
    "\n",
    "\t# randomly draw n trials from each session\n",
    "\tfor coh_idx, coh_val in enumerate(coh):\n",
    "\t\tequal_trials = np.where((trial_data['prob_toRF'] == 50) & (trial_data['stimulus'] == coh_val/100))[0]\n",
    "\t\tunequal_trials = np.where((trial_data['prob_toRF'] != 50) & (trial_data['stimulus'] == coh_val/100))[0]\n",
    "\n",
    "\t\tif session_metadata['prior_direction'].iloc[session_idx] == \"toRF\":\n",
    "\t\t\ttoRF_trial_indices['eq'].append(npr.choice(equal_trials, size=toRF_min_trial_per_condition[0, coh_idx], replace=False))\n",
    "\t\t\ttoRF_trial_indices['uneq'].append(npr.choice(unequal_trials, size=toRF_min_trial_per_condition[1, coh_idx], replace=False))\n",
    "\n",
    "\t\telif session_metadata['prior_direction'].iloc[session_idx] == \"awayRF\":\n",
    "\t\t\tawayRF_trial_indices['eq'].append(npr.choice(equal_trials, size=awayRF_min_trial_per_condition[0, coh_idx], replace=False))\n",
    "\t\t\tawayRF_trial_indices['uneq'].append(npr.choice(unequal_trials, size=awayRF_min_trial_per_condition[1, coh_idx], replace=False))\n",
    "\n",
    "\n",
    "\tif session_metadata['prior_direction'].iloc[session_idx] == \"toRF\":\n",
    "\t\tall_trial_indices = np.hstack(toRF_trial_indices['eq'] + toRF_trial_indices['uneq'])\n",
    "\t\tagg_toRF_neuron_data.append(get_session_neural_data(epoch=epoch, valid_trial_filter=all_trial_indices, neuron_ids=neuron_ids))\n",
    "\telif session_metadata['prior_direction'].iloc[session_idx] == \"awayRF\":\n",
    "\t\tall_trial_indices = np.hstack(awayRF_trial_indices['eq'] + awayRF_trial_indices['uneq'])\n",
    "\t\tagg_awayRF_neuron_data.append(get_session_neural_data(epoch=epoch, valid_trial_filter=all_trial_indices, neuron_ids=neuron_ids))\n",
    "\n",
    "agg_toRF_neuron_data = np.vstack(agg_toRF_neuron_data)\n",
    "agg_awayRF_neuron_data = np.vstack(agg_awayRF_neuron_data)\n",
    "agg_toRF_neuron_data.shape, agg_awayRF_neuron_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.matlib as matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_toRF = np.vstack((np.vstack([matlib.repmat(equal_prior,trial_num,1) for trial_num in toRF_min_trial_per_condition[0,:]]),\n",
    "                       np.vstack([matlib.repmat(toRF_prior,trial_num,1) for trial_num in toRF_min_trial_per_condition[1,:]])))\n",
    "\n",
    "prior_awayRF = np.vstack((np.vstack([matlib.repmat(equal_prior,trial_num,1) for trial_num in awayRF_min_trial_per_condition[0,:]]),\n",
    "                       np.vstack([matlib.repmat(awayRF_prior,trial_num,1) for trial_num in awayRF_min_trial_per_condition[1,:]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_toRF = np.repeat([coh,coh],toRF_min_trial_per_condition.flatten())\n",
    "t_awayRF = np.repeat([coh,coh],awayRF_min_trial_per_condition.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### toRF session fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_map = {stim: i for i, stim in enumerate(np.sort(coh))}\n",
    "delta = 1\n",
    "\n",
    "x = torch.tensor(np.nansum(agg_toRF_neuron_data[:, :, 200:300], axis=2).T, dtype=torch.float32, device=\"cuda\")\n",
    "t = torch.tensor([stim_map[stim] for stim in t_toRF], dtype=torch.long, device=\"cuda\")\n",
    "prior = torch.tensor(prior_toRF, dtype=torch.float32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.likelihood_models import FixedLikelihoodNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_full_likelihood_model(data_loader, hyperparameters):\n",
    "\t\"\"\"\n",
    "\tTrain the neural network on the full likelihood model with mini-batch training.\n",
    "\t\"\"\"\n",
    "\t# Unpack hyperparameters\n",
    "\tn_hidden = hyperparameters.get('n_hidden', [500, 500])\n",
    "\tn_epoch = hyperparameters.get('n_epoch', 1000)\n",
    "\tbatch_size = hyperparameters.get('batch_size', 32)\n",
    "\tlearning_rate = hyperparameters.get('learning_rate', 1e-3)\n",
    "\tweight_decay = hyperparameters.get('weight_decay', 1e-5)\n",
    "\tdropout = hyperparameters.get('dropout', 0.5)\n",
    "\tstd = hyperparameters.get('std', 0.001)\n",
    "\talpha = hyperparameters.get('alpha', 1.0)\n",
    "\tbeta = hyperparameters.get('beta', 1.0)\n",
    "\tloss_fn = hyperparameters.get('loss_fn', nn.CrossEntropyLoss().cuda())\n",
    "\n",
    "\t# Move data to GPU\n",
    "\tinput, target, prior = next(iter(train_loader))\n",
    "\n",
    "\n",
    "\t# Initialize Model\n",
    "\tnet = FixedLikelihoodNet(n_channel=input.shape[1], n_output=len(target.unique()), n_hidden=n_hidden, std=std, dropout=dropout)\n",
    "\tnet.cuda()\n",
    "\tnet.initialize()\n",
    "\n",
    "\toptimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\ttorch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tnet.train()\n",
    "\t\tepoch_loss = 0.0  # Track loss per epoch\n",
    "\n",
    "\t\tfor batch_input, batch_target, batch_prior in data_loader:\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\ty = net(batch_input)\n",
    "\n",
    "\t\t\t# Check for NaNs in output\n",
    "\t\t\tif torch.isnan(y).any() or torch.isinf(y).any():\n",
    "\t\t\t\tprint(f\"NaNs/Infs detected in output y at epoch {epoch}\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\tpost = y + batch_prior\n",
    "\t\t\tpost = post - post.max(1, keepdim=True)[0]  # Stabilize softmax\n",
    "\n",
    "\t\t\t# Check for NaNs in post\n",
    "\t\t\tif torch.isnan(post).any() or torch.isinf(post).any():\n",
    "\t\t\t\tprint(f\"NaNs/Infs detected in post at epoch {epoch}\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\tconv_filter = torch.tensor([-0.25, 0.5, -0.25], dtype=torch.float32, device=\"cuda\").reshape(1, 1, -1)\n",
    "\t\t\tsmoothness = nn.functional.conv1d(y.unsqueeze(1), conv_filter).pow(2).mean()\n",
    "\n",
    "\t\t\tif beta > 0:\n",
    "\t\t\t\tl2 = net.l2_weights_per_layer()\n",
    "\t\t\telse:\n",
    "\t\t\t\tl2 = 0\n",
    "\n",
    "\t\t\tloss = loss_fn(post, batch_target) + alpha * smoothness + beta * l2\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\n",
    "\t\t\t# Check for NaNs in loss\n",
    "\t\t\tif torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "\t\t\t\tprint(f\"NaNs/Infs detected in loss at epoch {epoch}\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t# Check gradients for NaNs\n",
    "\t\t\tfor param in net.parameters():\n",
    "\t\t\t\tif param.grad is not None and torch.isnan(param.grad).any():\n",
    "\t\t\t\t\tprint(\"NaNs detected in gradients\")\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t# # Apply gradient clipping\n",
    "\t\t\t# torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\tif epoch % 100 == 0:\n",
    "\t\t\tprint(f'Epoch {epoch}/{n_epoch}, Avg Loss: {epoch_loss / len(data_loader):.6f}')\n",
    "\n",
    "\treturn net, batch_input, batch_target, batch_prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x, t, prior)\n",
    "\n",
    "# Define the lengths for each split\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "val_size = int(0.15 * len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remainder for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Extract train_labels from train dataset\n",
    "train_labels = torch.tensor([dataset[i][1] for i in train_dataset.indices], dtype=torch.long)\n",
    "# Compute class frequencies\n",
    "labels, counts = torch.unique(train_labels, return_counts=True)\n",
    "class_weights = 1. / counts.float()  # Inverse frequency for each class\n",
    "sample_weights = class_weights[train_labels]  # Assign weight based on label index\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader with sampler (No shuffle needed)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "hyperparameters = {\n",
    "\t'n_hidden': [500, 500], # number of hidden units in each layer\n",
    "\t'n_epoch': 1000, # number of epochs\n",
    "\t'batch_size': 32, # batch size\n",
    "\t'learning_rate': 1e-3, # learning rate\n",
    "\t'weight_decay': 0,# 1e-6, # weight decay\n",
    "\t'dropout': 0.2, # dropout rate\n",
    "\t'std': 0.01, # std for initializing weights\n",
    "\t'alpha': 1.0, # weight on KL divergence term3\n",
    "\t'loss_fn': nn.CrossEntropyLoss(), # loss function\n",
    "\t'beta': 0.1 # weight on l2 normalization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500, Avg Loss: 1.942250\n",
      "Epoch 100/500, Avg Loss: 1.939286\n",
      "Epoch 200/500, Avg Loss: 1.942256\n",
      "Epoch 300/500, Avg Loss: 1.941013\n",
      "Epoch 400/500, Avg Loss: 1.943946\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'n_hidden': [1024, 512],\n",
    "    'n_epoch': 500,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 0.0,\n",
    "    'dropout': 0.5,\n",
    "    'std': 0.01,\n",
    "    'alpha': 0.0,  # turn off smoothness\n",
    "    'beta': 0.0,   # turn off L2\n",
    "    'loss_fn': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "\n",
    "net, input_train, target_train, prior_train = train_full_likelihood_model(train_loader, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.432989690721648, 26.21359223300971)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_val, target_val, prior_val = next(iter(val_loader))\n",
    "calculate_accuracy(net, input_train, prior_train, target_train), calculate_accuracy(net, input_val, prior_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1.98343657), array(2.08088853))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective(net, input_train, prior_train, target_train), objective(net, input_val, prior_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(net, x=None, prior=None, t=None):\n",
    "\tif x is None and t is None:\n",
    "\t\treturn None\n",
    "\tnet.eval()\n",
    "\ty = net(x)\n",
    "\tposterior = y + prior\n",
    "\t_, loc = torch.max(posterior, dim=1)\n",
    "\tv =(t.double() - loc.double()).pow(2).mean().sqrt() * delta\n",
    "\treturn v.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(net, x=None, prior=None, t=None):\n",
    "\t\"\"\"Calculate accuracy of the model\"\"\"\n",
    "\tt = t.cpu().numpy()\n",
    "\ty = net(x)+ prior\n",
    "\ty = y.data.cpu().numpy()\n",
    "\ty = np.exp(y)\n",
    "\ty = y / y.sum(axis=1, keepdims=True)\n",
    "\tpred = np.argmax(y, axis=1)\n",
    "\treturn np.mean(pred == t) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(input_val)\n",
    "y = y.data.cpu().numpy()\n",
    "y = np.exp(y)\n",
    "yd = y / y.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bin_width' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nbins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m----> 2\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43mbin_width\u001b[49m\n\u001b[1;32m      3\u001b[0m pv \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(nbins) \u001b[38;5;241m-\u001b[39m nbins\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m delta\n\u001b[1;32m      5\u001b[0m loc \u001b[38;5;241m=\u001b[39m yd\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bin_width' is not defined"
     ]
    }
   ],
   "source": [
    "nbins = 7\n",
    "\n",
    "pv = (np.arange(nbins) - nbins//2) * delta\n",
    "\n",
    "loc = yd.argmax(axis=1)\n",
    "ds = (np.arange(nbins) - loc[:, None])**2\n",
    "avg_sigma = np.mean(np.sqrt(np.sum(yd * ds, axis=1))) * delta\n",
    "\n",
    "n_rows = 5\n",
    "n_cols = 6\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(12, 12))\n",
    "for c, ((i, j), ax) in zip(count(), np.ndenumerate(axs)):\n",
    "    c = npr.randint(0, len(yd))  # Randomize to avoid deterministic behavior in plotting\n",
    "    ax.plot(pv, yd[c])\n",
    "    ax.scatter(pv[t_[c]],0.4, color='red', marker='x', s=1)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_yticks([])\n",
    "    if j == 0 and i == n_rows-1:\n",
    "        ax.set_ylabel('Likelihood (a.u.)')\n",
    "        ax.set_xlabel('Coherence (%)')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "fig.suptitle(\"$\\mathbf{{E}}[\\sigma]$={:0.3f}\".format(avg_sigma), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "coh_hat = np.array([pv[np.argmax(yd[i])] for i in range(len(yd))])\n",
    "plt.scatter(coh_hat, target_val.cpu()-3, color='blue', alpha=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
