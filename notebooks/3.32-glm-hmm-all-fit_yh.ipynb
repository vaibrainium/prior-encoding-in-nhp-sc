{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ssm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "from notebooks.imports import *\n",
    "from config import dir_config, main_config\n",
    "from src.utils.glm_hmm_utils import *\n",
    "compiled_dir = Path(dir_config.data.compiled)\n",
    "processed_dir = Path(dir_config.data.processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_previous_data(trial_data):\n",
    "    # npr.seed()\n",
    "    prev_choice = np.hstack([trial_data.choice[0] , trial_data.choice[:-1]])  # 0:awayRF, 1:toRF of previous valid trial\n",
    "    prev_target = np.hstack([trial_data.target[0] , trial_data.target[:-1]]) * 2 - 1 # -1:awayRF, 1:toRF of previous valid trial \n",
    "    prev_outcome = np.hstack([trial_data.outcome[0] , trial_data.outcome[:-1]])\n",
    "    prev_valid_idx = np.where(prev_outcome >= 0)[0]\n",
    "    prev_invalid_idx = np.where(prev_outcome == -1)[0]\n",
    "\n",
    "    for i in prev_invalid_idx:\n",
    "        if i < prev_valid_idx[0]: #randomly sample if no previous valid trials\n",
    "            prev_choice[i] = np.random.binomial(1,0.5)\n",
    "            prev_target[i] = np.random.binomial(1,0.5) * 2 - 1\n",
    "        else:\n",
    "            last_valid =  np.where(prev_valid_idx<i)[0][-1]\n",
    "            prev_choice[i] = prev_choice[prev_valid_idx[last_valid]]\n",
    "            prev_target[i] = prev_target[prev_valid_idx[last_valid]]\n",
    "    return prev_choice,prev_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2       # number of discrete states\n",
    "obs_dim = 1           # number of observed dimensions: choice(toRF/awayRF)\n",
    "num_categories = 2    # number of categories for output\n",
    "input_dim = 4        # input dimensions: current signed coherence, 1(bias), previous choice(toRF/awayRF), previous target side(toRF/awayRF)\n",
    "session_metadata = pd.read_csv(Path(compiled_dir, \"sessions_metadata.csv\"), index_col=None)\n",
    "inputs_session_wise = []\n",
    "choices_session_wise = []\n",
    "invalid_idx_session_wise = []\n",
    "masks_session_wise = []\n",
    "\n",
    "for session_id in (session_metadata['session_id']):\n",
    "\n",
    "    trial_data = pd.read_csv(Path(compiled_dir, session_id,f\"{session_id}_trial.csv\"), index_col=None).fillna(-1)\n",
    "    GP_trial_data = trial_data[trial_data.task_type == 1] #  all GP trials\n",
    "    # GP_trial_data = trial_data[(trial_data.task_type == 1) & (trial_data.outcome>=0)] #  valid GP trial\n",
    "    GP_trial_data = GP_trial_data.reset_index()\n",
    "    num_trials_per_sess = GP_trial_data.shape[0] # number of trials in a session\n",
    "    inpts = np.ones((1, num_trials_per_sess, input_dim)) # initialize inpts array\n",
    "\n",
    "    current_stimulus = GP_trial_data.coherence * (2*GP_trial_data.target-1)\n",
    "    inpts[0,:,0] = current_stimulus / 100\n",
    "    # inpts[0,:,0] = preprocessing.scale(inpts[0,:,0]) # normalize stim values\n",
    "\n",
    "    prev_choice,prev_target = extract_previous_data(GP_trial_data)\n",
    "    inpts[0,:,2] = prev_choice * 2- 1 # -1:awayRF, 1:toRF of previous valid trial\n",
    "    inpts[0,:,3] = prev_target # -1:awayRF, 1:toRF of previous valid trial\n",
    "\n",
    "    # inpts[0,:,2] = np.hstack([GP_trial_data.choice.iloc[0] , GP_trial_data.choice.iloc[:-1]]) *2-1 # -1:awayRF, 1:toRF choice of previous valid trial\n",
    "    # inpts[0,:,3] = np.hstack([GP_trial_data.target.iloc[0] , GP_trial_data.target.iloc[:-1]]) *2-1 # -1:awayRF, 1:toRF stim values of previous valid trial\n",
    "\n",
    "    inpts = list(inpts) #convert inpts to correct format\n",
    "    inputs_session_wise = inputs_session_wise + inpts\n",
    "\n",
    "    choices = GP_trial_data.choice.values\n",
    "    choices = choices.reshape(-1,1).astype('int')\n",
    "\n",
    "    masks = np.array(choices >= 0)\n",
    "    masks_session_wise.append(masks)\n",
    "    invalid_idx = np.where(choices == -1)[0].reshape(-1,1)\n",
    "    invalid_idx_session_wise.append(invalid_idx)\n",
    "\n",
    "    # for training, replace -1 with random sample from 0,1\n",
    "    choices[choices == -1] = npr.choice(1,invalid_idx.shape[0])\n",
    "    choices_session_wise.append(choices)\n",
    "\n",
    "inputs_aggregated = []\n",
    "inputs_aggregated.append(np.vstack(inputs_session_wise))\n",
    "choices_aggregated = []\n",
    "choices_aggregated.append(np.vstack(choices_session_wise))\n",
    "masks_aggregated = []\n",
    "masks_aggregated.append(np.vstack(masks_session_wise))\n",
    "\n",
    "# scaling signed coherence\n",
    "inputs_aggregated[0][:,0] = preprocessing.scale(inputs_aggregated[0][:, 0], axis=0)\n",
    "for idx_session in range(len(session_metadata)):\n",
    "    inputs_session_wise[idx_session][:,0] = preprocessing.scale(inputs_session_wise[idx_session][:, 0], axis=0) # normalize signed coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(Path(processed_dir, \"inputs_aggregated.pickle\"), 'rb') as handle:\n",
    "    inputs_aggregated = pickle.load(handle)\n",
    "with open(Path(processed_dir, \"choices_aggregated.pickle\"), 'rb') as handle:\n",
    "    choices_aggregated = pickle.load(handle)\n",
    "with open(Path(processed_dir, \"masks_aggregated.pickle\"), 'rb') as handle:\n",
    "    masks_aggregated = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3544b20fe147bfaed4c7f1b861cd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ssm\n",
    "\n",
    "def global_only_fit(observations, inputs, masks, state_range=np.arange(2, 6), n_initializations=20,\n",
    "               fitting_method='em', n_iters=200, tolerance=10**-4, n_jobs=-1):\n",
    "    glm = ssm.HMM(\n",
    "        1, observations[0].shape[1], inputs[0].shape[1],\n",
    "        observations=\"input_driven_obs\",\n",
    "        observation_kwargs=dict(C=len(np.unique(observations[0]))),\n",
    "        transitions=\"standard\"\n",
    "    )\n",
    "    glm.fit(observations, inputs=inputs, masks=masks, method=fitting_method, num_iters=n_iters, tolerance=tolerance)\n",
    "    \n",
    "global_only_fit(observations=choices_aggregated, inputs=inputs_aggregated, masks=masks_aggregated, state_range=[2], n_iters=2000, n_initializations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_glm_hmm, fit_lls_glm_hmm = global_fit(observations=choices_aggregated, inputs=inputs_aggregated, masks=masks_aggregated, n_iters=2000, n_initializations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model of 20 initializations for each state\n",
    "init_params = {\n",
    "    'glm_weights': {},\n",
    "    'transition_matrix': {}\n",
    "}\n",
    "for n_states in np.arange(2,6):\n",
    "    best_idx = np.argmax(fit_lls_glm_hmm[n_states])\n",
    "    init_params['glm_weights'][n_states] = models_glm_hmm[n_states][best_idx].observations.params\n",
    "    init_params['tranition_matrices'][n_states] = models_glm_hmm[n_states][best_idx].transitions.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit session-wise with 5 fold cross-validation\n",
    "models_session_state_fold, train_ll, test_ll = session_wise_fit_cv(observations=choices_session_wise, inputs=inputs_session_wise, masks=masks_session_wise\n",
    "                                                                   n_sessions=len(session_metadata), init_params=init_params, n_iters=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
