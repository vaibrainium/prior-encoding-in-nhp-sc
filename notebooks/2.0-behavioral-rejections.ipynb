{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fdcb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from notebooks.imports import *\n",
    "from config import dir_config, main_config\n",
    "from src.utils import pmf_utils, glm_hmm_utils\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec278c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_dir = Path(dir_config.data.compiled)\n",
    "processed_dir = Path(dir_config.data.processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d18b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_metadata = pd.read_csv(compiled_dir / 'sessions_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54794e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_previous_data(trial_data, valid_idx, first_trial, n_trial_back=3):\n",
    "\tnp.random.seed(1)\n",
    "\n",
    "\t# remove trials before the first valid trial or first three trials, whichever is larger\n",
    "\tprev_choice = np.empty((len(trial_data) - first_trial, n_trial_back), dtype=int)\n",
    "\tprev_target = np.empty((len(trial_data) - first_trial, n_trial_back), dtype=int)\n",
    "\n",
    "\t# Loop to populate prev_choice and prev_target with the last n_trial_back values for each trial\n",
    "\tfor i in range(first_trial, len(trial_data)):\n",
    "\t\t# Get the valid indices for the last n_trial_back trials\n",
    "\t\tvalid_indices = valid_idx[valid_idx < i][-n_trial_back:]  # Ensure we get the last n_trial_back valid trials\n",
    "\n",
    "\t\tprev_choice[i - first_trial] = trial_data.choice[valid_indices] * 2 - 1  # Convert choice to -1/1\n",
    "\t\tprev_target[i - first_trial] = trial_data.target[valid_indices] * 2 - 1  # Convert target to -1/1\n",
    "\n",
    "\n",
    "\treturn prev_choice, prev_target\n",
    "\n",
    "def prepare_input_data(data, input_dim, valid_idx, first_trial):\n",
    "\tif \"no_bias\" in _TRIALS:\n",
    "\t\tcurrent_trial_param = 1\n",
    "\telse:\n",
    "\t\tcurrent_trial_param = 2\n",
    "\tn_trial_back=(input_dim - current_trial_param) // 2\n",
    "\tX = np.ones((1, data.shape[0] - first_trial, input_dim))\n",
    "\n",
    "\tcurrent_stimulus = data.coherence * (2 * data.target - 1)\n",
    "\tcurrent_stimulus = current_stimulus / 100\n",
    "\n",
    "\tX[0, :, 0] = current_stimulus[first_trial:]  # current stimulus\n",
    "\tX[0, :, current_trial_param:current_trial_param+n_trial_back], X[0, :, current_trial_param+n_trial_back: current_trial_param+2*n_trial_back] = extract_previous_data(data, valid_idx, first_trial, n_trial_back=n_trial_back)\n",
    "\treturn list(X)\n",
    "\n",
    "# Remove Outliers\n",
    "def is_outlier_session(stimulus, choices, mask, prob_toRF):\n",
    "\tmask = np.ones_like(choices, dtype=bool) if mask is None else mask\n",
    "\tprob_toRF = prob_toRF[mask]\n",
    "\tindices = np.where((prob_toRF != 50) & ~np.isnan(prob_toRF))[0]\n",
    "\ttask_switch = indices[0] if len(indices) > 0 else 0\n",
    "\n",
    "\tequal_indices = np.where(mask)[0][:task_switch]\n",
    "\tunequal_indices = np.where(mask)[0][task_switch:]\n",
    "\teq_data = {\"signed_coherence\": np.array(stimulus[equal_indices]) * 100, \"choice\": choices[equal_indices]}\n",
    "\t_, _, eq_model, _, _ = pmf_utils.get_psychometric_data(eq_data)\n",
    "\tuneq_data = {\"signed_coherence\": np.array(stimulus[unequal_indices]) * 100, \"choice\": choices[unequal_indices]}\n",
    "\t_, _, uneq_model, _, _ = pmf_utils.get_psychometric_data(uneq_data)\n",
    "\n",
    "\tmean_diff = eq_model.coefs_[\"mean\"] - uneq_model.coefs_[\"mean\"]\n",
    "\tvar_diff = eq_model.coefs_[\"var\"] - uneq_model.coefs_[\"var\"]\n",
    "\n",
    "\tmean_threshold = main_config.rejection_criteria[\"mean_threshold\"]\n",
    "\tvar_threshold = main_config.rejection_criteria[\"var_threshold\"]\n",
    "\n",
    "\treturn mean_diff < mean_threshold and np.abs(var_diff) < var_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a862f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_sessions = []\n",
    "\n",
    "for _TRIALS in [\"all_trials\"]:\n",
    "\tn_states = 2  # number of discrete states\n",
    "\tobs_dim = 1  # number of observed dimensions: choice(toRF/awayRF)\n",
    "\tnum_categories = 2  # number of categories for output\n",
    "\n",
    "\tif \"no_bias\" in _TRIALS:\n",
    "\t\tcurrent_trial_param = 1\n",
    "\telse:\n",
    "\t\tcurrent_trial_param = 2\n",
    "\n",
    "\tn_trial_back = 1\n",
    "\n",
    "\tinput_dim = current_trial_param + 2*n_trial_back  # input dimensions: current signed coherence, 1(bias), previous choice(toRF/awayRF), previous target side(toRF/awayRF)\n",
    "\n",
    "\t# Pre-allocate lists for session data\n",
    "\tinputs_session_wise = []\n",
    "\tchoices_session_wise = []\n",
    "\tinvalid_idx_session_wise = []\n",
    "\tmasks_session_wise = []\n",
    "\tGP_trial_num_session_wise = []\n",
    "\tprob_toRF_session_wise = []\n",
    "\n",
    "\t# Pre-build a mapping from session_id to prior_direction for efficient lookup\n",
    "\tprior_direction_map = session_metadata.set_index(\"session_id\")[\"prior_direction\"].to_dict()\n",
    "\n",
    "\t# Process each session\n",
    "\tfor session_id in session_metadata[\"session_id\"]:\n",
    "\t\t# Read trial data for each session\n",
    "\t\ttrial_data = pd.read_csv(Path(compiled_dir, session_id, f\"{session_id}_trial.csv\"), index_col=None)\n",
    "\t\tGP_trial_data = trial_data[trial_data.task_type == 1].reset_index()\n",
    "\n",
    "\t\tif \"eq_prior\" in _TRIALS:\n",
    "\t\t\tGP_trial_data = GP_trial_data[GP_trial_data.prob_toRF == 50].reset_index()\n",
    "\n",
    "\t\t# Fill missing values for important columns\n",
    "\t\tGP_trial_data['choice'] = GP_trial_data.choice.fillna(-1)\n",
    "\t\tGP_trial_data['target'] = GP_trial_data.target.fillna(-1)\n",
    "\t\tGP_trial_data['outcome'] = GP_trial_data.outcome.fillna(-1)\n",
    "\n",
    "\t\t# Get valid indices based on outcomes\n",
    "\t\tvalid_idx = np.where(GP_trial_data.outcome >= 0)[0]\n",
    "\n",
    "\t\t# First valid trial considering n_trial_back\n",
    "\t\tfirst_trial = valid_idx[n_trial_back - 1] + 1\n",
    "\n",
    "\t\t# Prepare inputs and choices\n",
    "\t\tinputs = prepare_input_data(GP_trial_data, input_dim, valid_idx, first_trial)\n",
    "\t\tchoices = GP_trial_data.choice.values.reshape(-1, 1).astype(\"int\")\n",
    "\t\tchoices = choices[first_trial:]\n",
    "\n",
    "\t\t# Adjust invalid_idx and prepare mask\n",
    "\t\tinvalid_idx = np.where(choices == -1)[0]\n",
    "\n",
    "\t\tif \"all_trials\" in _TRIALS:\n",
    "\t\t\t# For training, replace -1 with a random sample from 0,1\n",
    "\t\t\tchoices[choices == -1] = np.random.choice(2, invalid_idx.shape[0])\n",
    "\n",
    "\t\t\t# Prepare mask\n",
    "\t\t\tmask = np.ones_like(choices, dtype=bool)\n",
    "\t\t\tmask[invalid_idx] = 0\n",
    "\n",
    "\t\t\t# Get trial numbers and prob_toRF for the cropped session\n",
    "\t\t\tGP_trial_num = np.array(GP_trial_data.trial_number)[first_trial:]\n",
    "\t\t\tprob_toRF = np.array(GP_trial_data.prob_toRF)[first_trial:]\n",
    "\t\telse:\n",
    "\t\t\tassert \"all_trials\" in _TRIALS, \"Invalid trials option\"\n",
    "\n",
    "\t\t# Check prior_direction for the current session and adjust inputs and choices\n",
    "\t\tprior_direction = prior_direction_map.get(session_id, 'awayRF')\n",
    "\t\tif prior_direction == 'awayRF':\n",
    "\t\t\tinputs[0][:, 0] = -inputs[0][:, 0]  # Flip the direction for input features\n",
    "\t\t\tinputs[0][:, 2:] = -inputs[0][:, 2:]\n",
    "\t\t\tchoices = 1-choices  # Flip the choices\n",
    "\n",
    "\t\tassert len(choices) == len(inputs[0]), f\"Length mismatch: {len(choices)} vs {len(inputs[0])}\"\n",
    "\t\tassert len(mask) == len(inputs[0]), f\"Length mismatch: {len(mask)} vs {len(inputs[0])}\"\n",
    "\t\tassert len(GP_trial_num) == len(inputs[0]), f\"Length mismatch: {len(GP_trial_num)} vs {len(inputs[0])}\"\n",
    "\t\tassert len(prob_toRF) == len(inputs[0]), f\"Length mismatch: {len(prob_toRF)} vs {len(inputs[0])}\"\n",
    "\n",
    "\t\tif is_outlier_session(inputs[0][:, 0], choices, mask[:,0], prob_toRF):\n",
    "\t\t\treject_sessions.append(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d976beed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['210216_GP_JP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reject_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ed1363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_metadata = session_metadata[~session_metadata.session_id.isin(reject_sessions)]\n",
    "\n",
    "session_metadata.to_csv(processed_dir / 'sessions_metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
